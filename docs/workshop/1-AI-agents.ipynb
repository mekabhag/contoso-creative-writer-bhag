{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order for the researcher to generate even better queries it needs to know which search functions are avaialble to it. \n",
    "- Using the Prompty **tools** parameter an LLM can choose from functions described in a json file. \n",
    "- We can add information about which functions (sometimes called tools), the LLM has access to in a **functions.json** file. \n",
    "- Information from a json file is passed to prompty using the  *${file:functions.json}* format. \n",
    "\n",
    "In the case of the researcher we have a **functions.json** file with descriptions of 3 functions:\n",
    "- find_information\n",
    "- find_entities\n",
    "- find_news\n",
    "\n",
    " [functions.json](./researcher/functions.json)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "> [researcher-2.prompty](researcher/researcher-2.prompty)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[ToolCall(id='call_0q85uP5rWqZ2cIsfu9HkcE0s', name='find_information', arguments='{\"query\":\"best educational material for learning Python programming\",\"market\":\"en-US\"}')]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import prompty\n",
    "import prompty.azure\n",
    "import os\n",
    "\n",
    "instructions = \"Can you find the best educational material for learning Python programming?\"\n",
    "prompty.execute(os.getcwd() + \"/researcher/researcher-2.prompty\", inputs={\"instructions\": instructions})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    ">   - In [researcher-2.prompty](researcher/researcher-2.prompty) *${file:functions.json}* has been added to **tools** under the *parameters* section in the  file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the result from running the Prompty file we saw that the **find_information** function was selected. \n",
    "- The LLM used the **instruction** we gave it and the **descriptions** it saw in *functions.json* to pick which function to call.  \n",
    "- It also figured out which parameter values should be passed to the function. \n",
    "\n",
    "We can influence which function is called by being more specific about the instructions we give the LLM.\n",
    "\n",
    "\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[ToolCall(id='call_smWD13KOyfeWVHGYY1QraTLU', name='find_entities', arguments='{\"query\":\"inventor of Python programming language\",\"market\":\"en-US\"}')]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "instructions = \"Who is the person who invented the Python programming language?\"\n",
    "prompty.execute(os.getcwd() + \"/researcher/researcher-2.prompty\", inputs={\"instructions\": instructions})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Note that the  **find_entities** function was selected by the LLM based on:\n",
    "> 1. **The description of the function** in [functions.json](./researcher/functions.json) \n",
    "> 2. The **instructions** we passed to it. \n",
    "\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[ToolCall(id='call_TVRC1SuEPEU183Cq3rsxChp1', name='find_information', arguments='{\"query\":\"Telus latest news\",\"market\":\"en-US\"}')]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "instructions = \"Find the latest news about Telus?\"\n",
    "prompty.execute(os.getcwd() + \"/researcher/researcher-2.prompty\", inputs={\"instructions\": instructions})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**find_news function description:**\n",
    "<details>\n",
    "\n",
    "```json\n",
    "{\n",
    "    \"type\": \"function\",\n",
    "    \"function\": {\n",
    "      \"name\": \"find_news\",\n",
    "      \"description\": \"Finds news on the web given a query. This function uses the Bing Search API to find news on the web given a query. The response includes the most relevant news articles from the web and should be used if you're looking for news.\",\n",
    "      \"parameters\": {\n",
    "        \"type\": \"object\",\n",
    "        \"properties\": {\n",
    "          \"query\": {\n",
    "            \"type\": \"string\",\n",
    "            \"description\": \"An optimal search query to find news on the web using the Bing Search API\"\n",
    "          },\n",
    "          \"market\": {\n",
    "            \"type\": \"string\",\n",
    "            \"description\": \"The market to search in, e.g. en-US - it should match the language of the query\"\n",
    "          }\n",
    "        },\n",
    "        \"required\": [\n",
    "          \"query\"\n",
    "        ]\n",
    "      }\n",
    "    }\n",
    "  }\n",
    "  ```\n",
    "  <details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "When we execute a Prompty file that has a **functions.json** file added to the **tools** parameter, the LLM returns a **list of Tool Calls** (also known as function calls) that look like this:\n",
    "\n",
    "```python\n",
    "[ToolCall(id='call_JtomZ3gCGHEa5MBxy6M3vypv', name='find_entities', arguments='{\"query\":\"inventor of Python programming language\",\"market\":\"en-US\"}')]\n",
    "```\n",
    "\n",
    "- The Python code for the functions described in *functions.json* can be found in the [researcher3.py](researcher/researcher3.py) file. \n",
    "- These functions will pass the query and market code to the Bing Search API.\n",
    "\n",
    "To put everything together the **research** function in [researcher3.py](researcher/researcher3.py) calls:\n",
    "-  an **execute_researcher_prompty** function that has the code we saw earlier to execute the prompty file \n",
    "- an **execute_function_calls** function that runs code to execute all the functions calls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "# Add the path to sys.path\n",
    "sys.path.append(os.path.abspath('../../docs/workshop/researcher'))\n",
    "\n",
    "from researcher3 import execute_researcher_prompty, execute_function_calls\n",
    "\n",
    "instructions = \"Can you find the best educational material for learning python programming?\"\n",
    "\n",
    "# Execute the researcher prompty to get a list of functions calls\n",
    "function_calls = execute_researcher_prompty(instructions=instructions)\n",
    "\n",
    "# Execute the function calls\n",
    "research = execute_function_calls(function_calls)\n",
    "research"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
